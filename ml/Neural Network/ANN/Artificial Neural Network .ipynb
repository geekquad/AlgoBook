{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the Data\n",
    "x = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[: , 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to make uncoding on city and gender for city we have to also use one hot encoding to avoid dummy trap\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# we convert categoris into numbers using label encoder\n",
    "\n",
    "#for City\n",
    "labelencode_x1 = LabelEncoder()\n",
    "x[:,1] = labelencode_x1.fit_transform(x[:,1])\n",
    "\n",
    "#for gender\n",
    "labelencode_x2 = LabelEncoder()\n",
    "x[:,2] = labelencode_x2.fit_transform(x[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now as you can see in city column we have three categoris to avoid high and lower value conflict we have to divid in categorical features\n",
    "# so we Use on Hot Encoding\n",
    "\n",
    "\n",
    "#here in column features we have to mention which column we have to categorize...\n",
    "# OneHotEncoder\n",
    "onehandencoder = ColumnTransformer([('one_hot_encoder', OneHotEncoder(categories='auto'), [1])],remainder='passthrough')   \n",
    "\n",
    "# The column numbers to be transformed (here is [0] but can be [0, 1, 3])                                        \n",
    "# Leave the rest of the columns untouched\n",
    "\n",
    "\n",
    "x = onehandencoder.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x # now it will perfact categorize and now we delete first row to avoid DUMMY VARIABLE TRAP\n",
    "\n",
    "x = x[ :,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1    2  3   4   5        6  7  8  9       10\n",
       "0     0  0  619  0  42   2        0  1  1  1   101349\n",
       "1     0  1  608  0  41   1  83807.9  1  0  1   112543\n",
       "2     0  0  502  0  42   8   159661  3  1  0   113932\n",
       "3     0  0  699  0  39   1        0  2  0  0  93826.6\n",
       "4     0  1  850  0  43   2   125511  1  1  1  79084.1\n",
       "...  .. ..  ... ..  ..  ..      ... .. .. ..      ...\n",
       "9995  0  0  771  1  39   5        0  2  1  0  96270.6\n",
       "9996  0  0  516  1  35  10  57369.6  1  1  1   101700\n",
       "9997  0  0  709  0  36   7        0  1  0  1  42085.6\n",
       "9998  1  0  772  1  42   3  75075.3  2  1  0  92888.5\n",
       "9999  0  0  792  0  28   4   130143  1  1  0  38190.8\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)  # for viewing purpose we convert it into frame as you can see first 2 col for city and 4 col for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now We can apply Split for train and test set..\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x, y , test_size =0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we required feature scaling must in ARTIFICIAL NEURAL NETWORKS because we have to to mane computation in mathemetical term\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler()\n",
    "x_train = x.fit_transform(x_train)\n",
    "x_test = x.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ...,\n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train # now every thing is scaled.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When we are using k cross fold this protion not run we have to run final part of progamme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout : It is a regualrization techinque used for to prevent overfitting.In this method we randmoly disabled some neurons while its complie so other neurons have to learn more hard so it prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrally overfitting occure when model occur high accuracy on train set rather then test set so it is high varience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dropout one argument is rate which means how many neurons you have to disable ex. for one neurons 0.1 for two 0.2 and so on..\n",
    "But When we apply above 0.5 rate then it genrate underfitting nerons not learn to much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libreries\n",
    "import keras\n",
    "from keras.models import Sequential # use for to intialize our ANN model\n",
    "from keras.layers import Dense # use for To create different layers in out Deep Model\n",
    "from keras.layers import Dropout # dropout regualarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", input_dim=11, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "## now we are intialize our model first\n",
    "# so we are creating object of Sequential class\n",
    "#dropout we have to add in layers\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "#here we create first layer using dense function\n",
    "# in dense we have to specify no. of hidden layer as units\n",
    "# which activation function use in hidden layers\n",
    "# how many input units for input layer as input_dim and this is COMPLUSORY TO specify..\n",
    "# init used to distributed weights of our model and which methos apply to distribut them that we have to specify..\n",
    "# input variable are nothing else but all independent variables\n",
    "\n",
    "classifier.add(Dense(units = 6 , activation='relu' , input_dim = 11 , init='uniform'))\n",
    "classifier.add(Dropout(rate = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# second time we don't need to mention input dim because calculate automatically from first layer \n",
    "# we choose activation as relu because it is not final laey it is also hidden layer..\n",
    "\n",
    "\n",
    "classifier.add(Dense(units = 6 , activation='relu', init='uniform'))\n",
    "classifier.add(Dropout(rate = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we have to categorize or output in more then two categorize then we have to use SOFTMAX() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# here we have units=1 because in our predictions we have only two categories so we mention units=1\n",
    "# activation = sigmoid because we need probabilities of our output\n",
    "# genrelly signmoid is very useful in binary classification...\n",
    "\n",
    "classifier.add(Dense(units = 1 , activation='sigmoid', init='uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complie the Model or Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimizer is used to stochistic gradient descent and method name is 'adam' so adam is stochistic gradient descent\n",
    "# loss is loss function binary_crossentropy use for binary classification and for more then features we use categorical_crossentropy\n",
    "# final agrument metrices is used to how our gradient descent decide next values as per accuracies so then next accuracy can increase\n",
    "# when weights are updated algorithem used this metrices of accuracy to improve the model\n",
    "\n",
    "\n",
    "classifier.compile(optimizer = 'adam' , loss ='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.4759 - accuracy: 0.7958\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4286 - accuracy: 0.7960\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4224 - accuracy: 0.7995\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4179 - accuracy: 0.8250\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.4163 - accuracy: 0.8276\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.4144 - accuracy: 0.8294\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4129 - accuracy: 0.8319\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4117 - accuracy: 0.8313\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4112 - accuracy: 0.8328\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4098 - accuracy: 0.8325\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4093 - accuracy: 0.8340\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4080 - accuracy: 0.8341\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4078 - accuracy: 0.8345\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4069 - accuracy: 0.8338\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4063 - accuracy: 0.8342\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4063 - accuracy: 0.8342\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.4058 - accuracy: 0.8356\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.4057 - accuracy: 0.8351\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4051 - accuracy: 0.8339\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4044 - accuracy: 0.8340\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4049 - accuracy: 0.8351\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4043 - accuracy: 0.8349\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4043 - accuracy: 0.8346\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4038 - accuracy: 0.8354\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4040 - accuracy: 0.8338\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4037 - accuracy: 0.8349\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.83 - 1s 83us/step - loss: 0.4033 - accuracy: 0.8346\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4031 - accuracy: 0.8340\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4028 - accuracy: 0.8342\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4027 - accuracy: 0.8354\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4027 - accuracy: 0.8346\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4025 - accuracy: 0.8351\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4026 - accuracy: 0.8360\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4020 - accuracy: 0.8341\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4021 - accuracy: 0.8351\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4017 - accuracy: 0.8350\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4021 - accuracy: 0.8350\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4023 - accuracy: 0.8345\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4017 - accuracy: 0.8344\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4013 - accuracy: 0.8349 0s - loss: 0.432\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4017 - accuracy: 0.8341\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4017 - accuracy: 0.8344\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4014 - accuracy: 0.8340 0s - loss: 0.407\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4013 - accuracy: 0.8355\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4015 - accuracy: 0.8336\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4013 - accuracy: 0.8350\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4014 - accuracy: 0.8338 0s - loss: 0\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.4011 - accuracy: 0.8341\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4014 - accuracy: 0.8341 0s - loss: 0.396\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4008 - accuracy: 0.8349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b732f10cc8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size is no. of observation after which you want to update your weights\n",
    "# epoch is a round when the whole training set pass through ANN.. & it is applying above steps over many epoch\n",
    "\n",
    "classifier.fit(x_train , y_train , batch_size=10 , epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.332753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.165915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.179191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.032298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.103744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.166711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.188118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.096750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.194568\n",
       "1     0.332753\n",
       "2     0.165915\n",
       "3     0.051355\n",
       "4     0.179191\n",
       "...        ...\n",
       "1995  0.032298\n",
       "1996  0.103744\n",
       "1997  0.166711\n",
       "1998  0.188118\n",
       "1999  0.096750\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5) # we are converting probabilities into true or flase so wen get calculated confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   False\n",
       "1   False\n",
       "2   False\n",
       "3   False\n",
       "4   False\n",
       "5    True\n",
       "6   False\n",
       "7   False\n",
       "8   False\n",
       "9    True\n",
       "10  False\n",
       "11  False\n",
       "12  False\n",
       "13  False\n",
       "14  False\n",
       "15  False\n",
       "16  False\n",
       "17  False\n",
       "18  False\n",
       "19  False\n",
       "20   True\n",
       "21  False\n",
       "22  False\n",
       "23  False\n",
       "24  False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x1b7345d3f08>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm  = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "%matplotlib notebook\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuract of Over all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are adding our data to predict customer is stay in bank or leave ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40 years old\n",
    "Tenure: 3 years\n",
    "Balance: $60000\n",
    "Number of Products: 2\n",
    "Does this customer have a credit card ? Yes\n",
    "Is this customer an Active Member: Yes\n",
    "Estimated Salary: $50000\n",
    "'''\n",
    "\n",
    "\n",
    "new_pred = classifier.predict(x.transform(np.array([[0,0,600,1,40,3,60000,2,1,1,50000]])))\n",
    "new_pred = (new_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    }
   ],
   "source": [
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluting Model of ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this evalution we are using k cross fold validation to check what is the correct accuracy of model. because every time we run the model it genrates different accuracies so we check it's accurary with help of K cross..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# in kerasclassifer one argument is build function so we create our ANN in bulid function and call it in kerasclassifier\n",
    "# in this case k corss is scikit learn class and Keras is different librarey so we use wrapper class of keras class\n",
    "# we are just taken above code in function.\n",
    "# NOTE : We are not including fit section in function because this task done by keras classifier\n",
    "# in this function classifer has scope of local so we create other classifier which scopes is global.\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6 , activation='relu' , input_dim = 11 , init='uniform'))\n",
    "    classifier.add(Dense(units = 6 , activation='relu', init='uniform'))\n",
    "    classifier.add(Dense(units = 1 , activation='sigmoid', init='uniform'))\n",
    "    classifier.compile(optimizer = 'adam' , loss ='binary_crossentropy' , metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn=build_classifier , batch_size=10 , epochs=50 )\n",
    "accuracies = cross_val_score(estimator=classifier , X=x_train , y = y_train , cv = 10 , n_jobs=-1)\n",
    "\n",
    "# estimator is classifeir name\n",
    "# cv is no. of fold or no of partition of trainset use for evealution\n",
    "# n_jobs is specially made for using all CPU power so it is use in DEEL LEARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83875   , 0.85124999, 0.83125001, 0.82125002, 0.84875   ,\n",
       "       0.85374999, 0.83625001, 0.82499999, 0.82249999, 0.84750003])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean & Varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = accuracies.mean()\n",
    "sd = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376250028610229"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011692009601523829"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we conclude that model has 83 % accuracy and 1.1 % varience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOW BIAS AND LOW VARIENCE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use grid search for this parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", input_dim=11, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.5550 - accuracy: 0.7949\n",
      "Epoch 2/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4368 - accuracy: 0.7960 0s - loss: 0.4624 - accuracy\n",
      "Epoch 3/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4315 - accuracy: 0.7960\n",
      "Epoch 4/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4286 - accuracy: 0.7960\n",
      "Epoch 5/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4268 - accuracy: 0.7960\n",
      "Epoch 6/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4244 - accuracy: 0.7960\n",
      "Epoch 7/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4215 - accuracy: 0.8025\n",
      "Epoch 8/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4193 - accuracy: 0.8211\n",
      "Epoch 9/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4179 - accuracy: 0.8231\n",
      "Epoch 10/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4163 - accuracy: 0.8264\n",
      "Epoch 11/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4153 - accuracy: 0.8276\n",
      "Epoch 12/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4140 - accuracy: 0.8299\n",
      "Epoch 13/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4132 - accuracy: 0.8309\n",
      "Epoch 14/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4123 - accuracy: 0.8306\n",
      "Epoch 15/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4112 - accuracy: 0.8310\n",
      "Epoch 16/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4107 - accuracy: 0.8330\n",
      "Epoch 17/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4101 - accuracy: 0.8338\n",
      "Epoch 18/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4096 - accuracy: 0.8326\n",
      "Epoch 19/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4090 - accuracy: 0.8339\n",
      "Epoch 20/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4086 - accuracy: 0.8346\n",
      "Epoch 21/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4076 - accuracy: 0.8330\n",
      "Epoch 22/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4073 - accuracy: 0.8339\n",
      "Epoch 23/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4069 - accuracy: 0.8340\n",
      "Epoch 24/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4063 - accuracy: 0.8349\n",
      "Epoch 25/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4060 - accuracy: 0.8342\n",
      "Epoch 26/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4013 - accuracy: 0.83 - 0s 31us/step - loss: 0.4055 - accuracy: 0.8350\n",
      "Epoch 27/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4052 - accuracy: 0.8342\n",
      "Epoch 28/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4048 - accuracy: 0.8353\n",
      "Epoch 29/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4048 - accuracy: 0.8357\n",
      "Epoch 30/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4045 - accuracy: 0.8346\n",
      "Epoch 31/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4041 - accuracy: 0.8353 0s - loss: 0.4066 - accuracy: \n",
      "Epoch 32/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4040 - accuracy: 0.8355\n",
      "Epoch 33/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4039 - accuracy: 0.8342\n",
      "Epoch 34/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4037 - accuracy: 0.8356\n",
      "Epoch 35/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4034 - accuracy: 0.8346\n",
      "Epoch 36/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4032 - accuracy: 0.8355\n",
      "Epoch 37/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4030 - accuracy: 0.8356\n",
      "Epoch 38/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4031 - accuracy: 0.8361\n",
      "Epoch 39/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4028 - accuracy: 0.8356\n",
      "Epoch 40/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4028 - accuracy: 0.8353\n",
      "Epoch 41/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4024 - accuracy: 0.8350\n",
      "Epoch 42/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4026 - accuracy: 0.8345\n",
      "Epoch 43/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4023 - accuracy: 0.8351\n",
      "Epoch 44/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4023 - accuracy: 0.8365\n",
      "Epoch 45/500\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.4021 - accuracy: 0.8370\n",
      "Epoch 46/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4020 - accuracy: 0.8357\n",
      "Epoch 47/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4019 - accuracy: 0.8350\n",
      "Epoch 48/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4018 - accuracy: 0.8347\n",
      "Epoch 49/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4019 - accuracy: 0.8350\n",
      "Epoch 50/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4015 - accuracy: 0.8349\n",
      "Epoch 51/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4015 - accuracy: 0.8345\n",
      "Epoch 52/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4014 - accuracy: 0.8344\n",
      "Epoch 53/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4011 - accuracy: 0.8351\n",
      "Epoch 54/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4016 - accuracy: 0.8361\n",
      "Epoch 55/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4012 - accuracy: 0.8345\n",
      "Epoch 56/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4011 - accuracy: 0.8355\n",
      "Epoch 57/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4010 - accuracy: 0.8354\n",
      "Epoch 58/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4015 - accuracy: 0.8344\n",
      "Epoch 59/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4008 - accuracy: 0.8340\n",
      "Epoch 60/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4011 - accuracy: 0.8349\n",
      "Epoch 61/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4011 - accuracy: 0.8346\n",
      "Epoch 62/500\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.4009 - accuracy: 0.8354\n",
      "Epoch 63/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4007 - accuracy: 0.8355\n",
      "Epoch 64/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4006 - accuracy: 0.8342\n",
      "Epoch 65/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4004 - accuracy: 0.8353\n",
      "Epoch 66/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4007 - accuracy: 0.8356\n",
      "Epoch 67/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4009 - accuracy: 0.8363 0s - loss: 0.4179 - accuracy\n",
      "Epoch 68/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4007 - accuracy: 0.8344 0s - loss: 0.3933 - accuracy\n",
      "Epoch 69/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4007 - accuracy: 0.8349\n",
      "Epoch 70/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8349\n",
      "Epoch 71/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4007 - accuracy: 0.8355\n",
      "Epoch 72/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8361\n",
      "Epoch 73/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8361 0s - loss: 0.4049 - accuracy: 0.\n",
      "Epoch 74/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8355\n",
      "Epoch 75/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4004 - accuracy: 0.8340\n",
      "Epoch 76/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4002 - accuracy: 0.8345\n",
      "Epoch 77/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8354\n",
      "Epoch 78/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4002 - accuracy: 0.8350\n",
      "Epoch 79/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8356\n",
      "Epoch 80/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8351\n",
      "Epoch 81/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8338\n",
      "Epoch 82/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4004 - accuracy: 0.8346\n",
      "Epoch 83/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8354\n",
      "Epoch 84/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8349\n",
      "Epoch 85/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8355\n",
      "Epoch 86/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8359\n",
      "Epoch 87/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4001 - accuracy: 0.8346\n",
      "Epoch 88/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4003 - accuracy: 0.8346\n",
      "Epoch 89/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3999 - accuracy: 0.8340\n",
      "Epoch 90/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3999 - accuracy: 0.8359\n",
      "Epoch 91/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4002 - accuracy: 0.8341\n",
      "Epoch 92/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8341\n",
      "Epoch 93/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8356\n",
      "Epoch 94/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8345\n",
      "Epoch 95/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8356\n",
      "Epoch 96/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8355\n",
      "Epoch 97/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8345\n",
      "Epoch 98/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3997 - accuracy: 0.8347\n",
      "Epoch 99/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8346\n",
      "Epoch 100/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8342\n",
      "Epoch 101/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4000 - accuracy: 0.8356\n",
      "Epoch 102/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3997 - accuracy: 0.8356\n",
      "Epoch 103/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8345\n",
      "Epoch 104/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4002 - accuracy: 0.8355\n",
      "Epoch 105/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3999 - accuracy: 0.8359\n",
      "Epoch 106/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8353\n",
      "Epoch 107/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8350\n",
      "Epoch 108/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8357\n",
      "Epoch 109/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8351\n",
      "Epoch 110/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3999 - accuracy: 0.8335\n",
      "Epoch 111/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8354\n",
      "Epoch 112/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8363\n",
      "Epoch 113/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8340\n",
      "Epoch 114/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8351\n",
      "Epoch 115/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8353\n",
      "Epoch 116/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8339\n",
      "Epoch 117/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8353\n",
      "Epoch 118/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8346 0s - loss: 0.4037 - accuracy: \n",
      "Epoch 119/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8356\n",
      "Epoch 120/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8342\n",
      "Epoch 121/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8353\n",
      "Epoch 122/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3999 - accuracy: 0.8350\n",
      "Epoch 123/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8347\n",
      "Epoch 124/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8353\n",
      "Epoch 125/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8332\n",
      "Epoch 126/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4001 - accuracy: 0.8338\n",
      "Epoch 127/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3994 - accuracy: 0.8361\n",
      "Epoch 128/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8353\n",
      "Epoch 129/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8341\n",
      "Epoch 130/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8356\n",
      "Epoch 131/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3998 - accuracy: 0.8342 0s - loss: 0.4033 - accuracy: \n",
      "Epoch 132/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8351\n",
      "Epoch 133/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8338\n",
      "Epoch 134/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8349\n",
      "Epoch 135/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8342\n",
      "Epoch 136/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3999 - accuracy: 0.8340\n",
      "Epoch 137/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3992 - accuracy: 0.8356\n",
      "Epoch 138/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8339\n",
      "Epoch 139/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8347\n",
      "Epoch 140/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8354\n",
      "Epoch 141/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 142/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8353\n",
      "Epoch 143/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8340\n",
      "Epoch 144/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8364\n",
      "Epoch 145/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3994 - accuracy: 0.8347\n",
      "Epoch 146/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8331\n",
      "Epoch 147/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 148/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 149/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8353\n",
      "Epoch 150/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8355\n",
      "Epoch 151/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8353\n",
      "Epoch 152/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8345\n",
      "Epoch 153/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8341\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8355\n",
      "Epoch 155/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8345\n",
      "Epoch 156/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8345\n",
      "Epoch 157/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.83 - 0s 32us/step - loss: 0.3992 - accuracy: 0.8354\n",
      "Epoch 158/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3994 - accuracy: 0.8340\n",
      "Epoch 159/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8354\n",
      "Epoch 160/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8353\n",
      "Epoch 161/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 162/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8345\n",
      "Epoch 163/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8350\n",
      "Epoch 164/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3991 - accuracy: 0.8359\n",
      "Epoch 165/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3991 - accuracy: 0.8349\n",
      "Epoch 166/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8340\n",
      "Epoch 167/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 168/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3998 - accuracy: 0.8338\n",
      "Epoch 169/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3986 - accuracy: 0.8349\n",
      "Epoch 170/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8364\n",
      "Epoch 171/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3994 - accuracy: 0.8349\n",
      "Epoch 172/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 173/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 174/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8360\n",
      "Epoch 175/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8340\n",
      "Epoch 176/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8351\n",
      "Epoch 177/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 178/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3997 - accuracy: 0.8332\n",
      "Epoch 179/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 180/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8340\n",
      "Epoch 181/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8351\n",
      "Epoch 182/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8344\n",
      "Epoch 183/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 184/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 185/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 186/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 187/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8335\n",
      "Epoch 188/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 189/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3996 - accuracy: 0.8334\n",
      "Epoch 190/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8360\n",
      "Epoch 191/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 192/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3995 - accuracy: 0.8344\n",
      "Epoch 193/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8342\n",
      "Epoch 194/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 195/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8344\n",
      "Epoch 196/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8346\n",
      "Epoch 197/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3995 - accuracy: 0.8345\n",
      "Epoch 198/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3997 - accuracy: 0.8338\n",
      "Epoch 199/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8350\n",
      "Epoch 200/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3996 - accuracy: 0.8347 0s - loss: 0.4125 - accuracy: \n",
      "Epoch 201/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 202/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 203/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3996 - accuracy: 0.8346\n",
      "Epoch 204/500\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.3994 - accuracy: 0.8338\n",
      "Epoch 205/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 206/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3996 - accuracy: 0.8353\n",
      "Epoch 207/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8349\n",
      "Epoch 208/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3994 - accuracy: 0.8354\n",
      "Epoch 209/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8359\n",
      "Epoch 210/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8331\n",
      "Epoch 211/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 212/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8355\n",
      "Epoch 213/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8338\n",
      "Epoch 214/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8354\n",
      "Epoch 215/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3996 - accuracy: 0.8345\n",
      "Epoch 216/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3991 - accuracy: 0.8339\n",
      "Epoch 217/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 218/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 219/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3996 - accuracy: 0.8349\n",
      "Epoch 220/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3988 - accuracy: 0.8353\n",
      "Epoch 221/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8349\n",
      "Epoch 222/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8342\n",
      "Epoch 223/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8342\n",
      "Epoch 224/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 225/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 226/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 227/500\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 228/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3989 - accuracy: 0.8342\n",
      "Epoch 229/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 230/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3993 - accuracy: 0.8349\n",
      "Epoch 231/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3995 - accuracy: 0.8354\n",
      "Epoch 232/500\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.3993 - accuracy: 0.8342\n",
      "Epoch 233/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 234/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8351\n",
      "Epoch 235/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3993 - accuracy: 0.8336\n",
      "Epoch 236/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8349 0s - loss: 0.3\n",
      "Epoch 237/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3992 - accuracy: 0.8356\n",
      "Epoch 238/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8349\n",
      "Epoch 239/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3991 - accuracy: 0.8349\n",
      "Epoch 240/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3994 - accuracy: 0.8349\n",
      "Epoch 241/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 242/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3989 - accuracy: 0.8354\n",
      "Epoch 243/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3993 - accuracy: 0.8344\n",
      "Epoch 244/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 245/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3994 - accuracy: 0.8359\n",
      "Epoch 246/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3996 - accuracy: 0.8347\n",
      "Epoch 247/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3993 - accuracy: 0.8361\n",
      "Epoch 248/500\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 249/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3997 - accuracy: 0.8341\n",
      "Epoch 250/500\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3993 - accuracy: 0.8344\n",
      "Epoch 251/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8334\n",
      "Epoch 252/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3994 - accuracy: 0.8356\n",
      "Epoch 253/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3995 - accuracy: 0.8359\n",
      "Epoch 254/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3991 - accuracy: 0.8335\n",
      "Epoch 255/500\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 256/500\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3993 - accuracy: 0.8342\n",
      "Epoch 257/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3991 - accuracy: 0.8332\n",
      "Epoch 258/500\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 259/500\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3994 - accuracy: 0.8351\n",
      "Epoch 260/500\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 261/500\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3989 - accuracy: 0.8347\n",
      "Epoch 262/500\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 263/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 264/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 265/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3993 - accuracy: 0.8335\n",
      "Epoch 266/500\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 267/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 268/500\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.3991 - accuracy: 0.8340\n",
      "Epoch 269/500\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3994 - accuracy: 0.8349\n",
      "Epoch 270/500\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3996 - accuracy: 0.8353\n",
      "Epoch 271/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3994 - accuracy: 0.8345\n",
      "Epoch 272/500\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3995 - accuracy: 0.8350\n",
      "Epoch 273/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 274/500\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3992 - accuracy: 0.8344\n",
      "Epoch 275/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 276/500\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3992 - accuracy: 0.8339\n",
      "Epoch 277/500\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3994 - accuracy: 0.8351\n",
      "Epoch 278/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 279/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8350\n",
      "Epoch 280/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3993 - accuracy: 0.8355\n",
      "Epoch 281/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8353\n",
      "Epoch 282/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3990 - accuracy: 0.8334\n",
      "Epoch 283/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3991 - accuracy: 0.8340\n",
      "Epoch 284/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 285/500\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 286/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3990 - accuracy: 0.8338\n",
      "Epoch 287/500\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3991 - accuracy: 0.8350\n",
      "Epoch 288/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8332\n",
      "Epoch 289/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8342\n",
      "Epoch 290/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3995 - accuracy: 0.8346\n",
      "Epoch 291/500\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3992 - accuracy: 0.8342\n",
      "Epoch 292/500\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8340\n",
      "Epoch 293/500\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.3994 - accuracy: 0.8353 0s - loss: 0.4148 - accura\n",
      "Epoch 294/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8334\n",
      "Epoch 295/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8335\n",
      "Epoch 296/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8353 0s - loss: 0.3856 - accura\n",
      "Epoch 297/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 298/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 299/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8353\n",
      "Epoch 300/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3988 - accuracy: 0.8339\n",
      "Epoch 301/500\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.3995 - accuracy: 0.8344\n",
      "Epoch 302/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3988 - accuracy: 0.8341\n",
      "Epoch 303/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.83 - 0s 36us/step - loss: 0.3997 - accuracy: 0.8356\n",
      "Epoch 304/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8355 0s - loss: 0.4041 - accuracy: 0.\n",
      "Epoch 305/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8350\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3997 - accuracy: 0.8346\n",
      "Epoch 307/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8342\n",
      "Epoch 308/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8340\n",
      "Epoch 309/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3989 - accuracy: 0.8353\n",
      "Epoch 310/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8341\n",
      "Epoch 311/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 312/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8341\n",
      "Epoch 313/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8346\n",
      "Epoch 314/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3994 - accuracy: 0.8344\n",
      "Epoch 315/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8341\n",
      "Epoch 316/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8353\n",
      "Epoch 317/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8344\n",
      "Epoch 318/500\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3993 - accuracy: 0.8339\n",
      "Epoch 319/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 320/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8345\n",
      "Epoch 321/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 322/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8353\n",
      "Epoch 323/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8346\n",
      "Epoch 324/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3988 - accuracy: 0.8347\n",
      "Epoch 325/500\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 326/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8338\n",
      "Epoch 327/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8351\n",
      "Epoch 328/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 329/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 330/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3993 - accuracy: 0.8344\n",
      "Epoch 331/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8347\n",
      "Epoch 332/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8342\n",
      "Epoch 333/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 334/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8335\n",
      "Epoch 335/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8339\n",
      "Epoch 336/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8335\n",
      "Epoch 337/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8349\n",
      "Epoch 338/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8340\n",
      "Epoch 339/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8332\n",
      "Epoch 340/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8338\n",
      "Epoch 341/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 342/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 343/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8339\n",
      "Epoch 344/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 345/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 346/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 347/500\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3992 - accuracy: 0.8355\n",
      "Epoch 348/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 349/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3989 - accuracy: 0.8345\n",
      "Epoch 350/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 351/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3991 - accuracy: 0.8349\n",
      "Epoch 352/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3995 - accuracy: 0.8355\n",
      "Epoch 353/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 354/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3991 - accuracy: 0.8340\n",
      "Epoch 355/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3986 - accuracy: 0.8359\n",
      "Epoch 356/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3992 - accuracy: 0.8341\n",
      "Epoch 357/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8346\n",
      "Epoch 358/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3991 - accuracy: 0.8355\n",
      "Epoch 359/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3995 - accuracy: 0.8351\n",
      "Epoch 360/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3988 - accuracy: 0.8354\n",
      "Epoch 361/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 362/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3991 - accuracy: 0.8354\n",
      "Epoch 363/500\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3991 - accuracy: 0.8355\n",
      "Epoch 364/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3991 - accuracy: 0.8336\n",
      "Epoch 365/500\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.3994 - accuracy: 0.8344\n",
      "Epoch 366/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3991 - accuracy: 0.8355\n",
      "Epoch 367/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3989 - accuracy: 0.8345\n",
      "Epoch 368/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3993 - accuracy: 0.8342\n",
      "Epoch 369/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3991 - accuracy: 0.8355\n",
      "Epoch 370/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3997 - accuracy: 0.8350\n",
      "Epoch 371/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3995 - accuracy: 0.8329\n",
      "Epoch 372/500\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.3992 - accuracy: 0.8342\n",
      "Epoch 373/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3992 - accuracy: 0.8340\n",
      "Epoch 374/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8346\n",
      "Epoch 375/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8345\n",
      "Epoch 376/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8341\n",
      "Epoch 377/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3991 - accuracy: 0.8351\n",
      "Epoch 378/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3995 - accuracy: 0.8356\n",
      "Epoch 379/500\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 380/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8338\n",
      "Epoch 381/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3988 - accuracy: 0.8349\n",
      "Epoch 382/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3991 - accuracy: 0.8363\n",
      "Epoch 383/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3991 - accuracy: 0.8346\n",
      "Epoch 384/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8345\n",
      "Epoch 385/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8345\n",
      "Epoch 386/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 387/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3991 - accuracy: 0.8349 0s - loss: 0.3960 - accuracy\n",
      "Epoch 388/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3992 - accuracy: 0.8344 0s - loss: 0.3959 - accuracy: 0.\n",
      "Epoch 389/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3989 - accuracy: 0.8344\n",
      "Epoch 390/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3991 - accuracy: 0.8341\n",
      "Epoch 391/500\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3992 - accuracy: 0.8344\n",
      "Epoch 392/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8357\n",
      "Epoch 393/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3993 - accuracy: 0.8336\n",
      "Epoch 394/500\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3990 - accuracy: 0.8355 0s - loss: 0.3939 - accuracy: \n",
      "Epoch 395/500\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3990 - accuracy: 0.8341\n",
      "Epoch 396/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3990 - accuracy: 0.8340\n",
      "Epoch 397/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8346\n",
      "Epoch 398/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8342\n",
      "Epoch 399/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3987 - accuracy: 0.8338\n",
      "Epoch 400/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8356\n",
      "Epoch 401/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 402/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3990 - accuracy: 0.8340\n",
      "Epoch 403/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8353\n",
      "Epoch 404/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3993 - accuracy: 0.8340\n",
      "Epoch 405/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8349\n",
      "Epoch 406/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8336\n",
      "Epoch 407/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8351\n",
      "Epoch 408/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3989 - accuracy: 0.8346\n",
      "Epoch 409/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8349\n",
      "Epoch 410/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3993 - accuracy: 0.8340\n",
      "Epoch 411/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3996 - accuracy: 0.8335\n",
      "Epoch 412/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3994 - accuracy: 0.8347\n",
      "Epoch 413/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8347 0s - loss: 0.4168 - accuracy\n",
      "Epoch 414/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8349\n",
      "Epoch 415/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8341\n",
      "Epoch 416/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 417/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8346 0s - loss: 0.3883 - accura\n",
      "Epoch 418/500\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3993 - accuracy: 0.8335\n",
      "Epoch 419/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 420/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3991 - accuracy: 0.8359\n",
      "Epoch 421/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8346\n",
      "Epoch 422/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3988 - accuracy: 0.8355\n",
      "Epoch 423/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8353\n",
      "Epoch 424/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3992 - accuracy: 0.8356\n",
      "Epoch 425/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3990 - accuracy: 0.8341\n",
      "Epoch 426/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 427/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8345\n",
      "Epoch 428/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3994 - accuracy: 0.8344\n",
      "Epoch 429/500\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.83 - 1s 72us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 430/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8344\n",
      "Epoch 431/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3989 - accuracy: 0.8339\n",
      "Epoch 432/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - accuracy: 0.8349\n",
      "Epoch 433/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 434/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 435/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8339\n",
      "Epoch 436/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 437/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3990 - accuracy: 0.8345\n",
      "Epoch 438/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3989 - accuracy: 0.8350\n",
      "Epoch 439/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 440/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8350\n",
      "Epoch 441/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8350\n",
      "Epoch 442/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8351\n",
      "Epoch 443/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8351\n",
      "Epoch 444/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3989 - accuracy: 0.8331\n",
      "Epoch 445/500\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3992 - accuracy: 0.8354\n",
      "Epoch 446/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3992 - accuracy: 0.8361\n",
      "Epoch 447/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3992 - accuracy: 0.8340\n",
      "Epoch 448/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - accuracy: 0.8338\n",
      "Epoch 449/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 450/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - accuracy: 0.8363\n",
      "Epoch 451/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3991 - accuracy: 0.8355\n",
      "Epoch 452/500\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - accuracy: 0.8344\n",
      "Epoch 453/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 454/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3989 - accuracy: 0.8336\n",
      "Epoch 455/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8344\n",
      "Epoch 456/500\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 457/500\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3993 - accuracy: 0.8345\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 459/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 460/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8334\n",
      "Epoch 461/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3990 - accuracy: 0.8346\n",
      "Epoch 462/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 463/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8359\n",
      "Epoch 464/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8357\n",
      "Epoch 465/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 466/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8347\n",
      "Epoch 467/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3990 - accuracy: 0.8351\n",
      "Epoch 468/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8342\n",
      "Epoch 469/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8346\n",
      "Epoch 470/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8349\n",
      "Epoch 471/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3991 - accuracy: 0.8349\n",
      "Epoch 472/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3990 - accuracy: 0.8350\n",
      "Epoch 473/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8341\n",
      "Epoch 474/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3994 - accuracy: 0.8347\n",
      "Epoch 475/500\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3988 - accuracy: 0.8350\n",
      "Epoch 476/500\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3992 - accuracy: 0.8347\n",
      "Epoch 477/500\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3994 - accuracy: 0.8353\n",
      "Epoch 478/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3995 - accuracy: 0.8342\n",
      "Epoch 479/500\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.3988 - accuracy: 0.8349\n",
      "Epoch 480/500\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.3990 - accuracy: 0.8345\n",
      "Epoch 481/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8329\n",
      "Epoch 482/500\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8345\n",
      "Epoch 483/500\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3993 - accuracy: 0.8344\n",
      "Epoch 484/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3990 - accuracy: 0.8339\n",
      "Epoch 485/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3991 - accuracy: 0.8350\n",
      "Epoch 486/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3991 - accuracy: 0.8347\n",
      "Epoch 487/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3988 - accuracy: 0.8350\n",
      "Epoch 488/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3986 - accuracy: 0.8341\n",
      "Epoch 489/500\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3991 - accuracy: 0.8341\n",
      "Epoch 490/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3992 - accuracy: 0.8339\n",
      "Epoch 491/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3989 - accuracy: 0.8346\n",
      "Epoch 492/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3990 - accuracy: 0.8339\n",
      "Epoch 493/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3991 - accuracy: 0.8351\n",
      "Epoch 494/500\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.3993 - accuracy: 0.8341\n",
      "Epoch 495/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3992 - accuracy: 0.8349\n",
      "Epoch 496/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3989 - accuracy: 0.8341\n",
      "Epoch 497/500\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3992 - accuracy: 0.8344\n",
      "Epoch 498/500\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3991 - accuracy: 0.8341\n",
      "Epoch 499/500\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3994 - accuracy: 0.8356\n",
      "Epoch 500/500\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3991 - accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6 , activation='relu' , input_dim = 11 , init='uniform'))\n",
    "    classifier.add(Dense(units = 6 , activation='relu', init='uniform'))\n",
    "    classifier.add(Dense(units = 1 , activation='sigmoid', init='uniform'))\n",
    "    classifier.compile(optimizer = 'adam' , loss ='binary_crossentropy' , metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn=build_classifier) # here we are not meintion epochs and batch-size we find it by GridSearchCV\n",
    "parameters = {'batch_size':[20,25,35,40],\n",
    "              'epochs':[50,100,150,500],\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier ,\n",
    "                          param_grid= parameters,\n",
    "                          cv = 10,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='accuracy')\n",
    "\n",
    "grid_search = grid_search.fit(x_train , y_train)\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527500000000001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25, 'epochs': 500}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
